
## 机器学习基本概述

### 机器学习本质与定义

**本质**：通过大量数据训练，让计算机自动发现数据中的规律，**学习到一个函数（模型）**。

**示例**：

1. **语音识别**：识别一段音频信号对应的文本内容。

2. **图像识别**：输入一张数字图片（如手写的数字"7"的像素矩阵），输出图片中物体的类别（"7"）。




### 机器学习的分类

#### 分类（classification）

**定义**：给定一些预定义的类别（class）和待分类的样本，输出样本所属的类别（离散的类别标签，而非连续的数值）。

**示例**：

1. **垃圾邮件分类**（二分类）：根据一封邮件的内容，判断邮件类别（是否为垃圾邮件）。

2. **手写数字识别**（多分类）：根据一张手写数字的图片，判断数字类别（0, 1, 2, ..., 9）。


#### 回归（regression）

**定义**：函数输出一个连续的数值（标量或向量）。

**示例**：

1. **空气质量预测**：根据今天中午的PM2.5浓度（50 μg/m³）、气温（25°C）、O₃浓度（80 μg/m³），预测明天中午的PM2.5浓度预测值（如45 μg/m³）

2. **房价预测**：根据房屋特征（面积、位置、楼层），预测房屋价格预测值


#### 结构化学习（structured learning）

**定义**：产生一个结构化的物体，比如画一张图片、写一篇文档。

**示例**：根据文本描述生成图像，输入一段文字描述，输出对应的图片。




## 机器学习流程 -- 以 `youtube` 视频的观看量为例

下面以 `youtube` 视频的观看量预测为研究场景，探究机器学习中的函数（模型）、损失函数的定义，以及问题求解的一般过程。

**问题描述**：在 `youtube` 平台中，根据视频的各种特征（标题长度、发布时间、视频时长、前一天的观看量等），预测发布后某一天的观看量预测值。



### 模型定义与设计

#### 建立数学模型

假设观察到视频观看量的某种规律，比如：前一天观看量高的视频，第二天观看量也可能较高，也就是前一天视频观看量与第二天的视频观看量有一定相关性。

基于此，设计一个简单线性模型：$$y = b + wx_1$$

上式中，$y$ 表示要预测的第二天的视频观看量；$x_1$ 表示前一天的视频观看量；$w$ 为**权重**，表示前一天观看量对第二天观看量的影响程度；$b$ 为**偏置**，表示基础观看量。其中，**权重（weight）$w$** 控制特征对预测结果的影响程度，为正数表示为正相关，反之为负相关，绝对值越大影响越强。

需要注意的是，模型（函数）的设计需要结合**领域知识（domain knowledge）**。比如：视频观看量通常不会为负数，所以模型应该保证输出为正；观看量可能存在周期性（工作日vs周末）。




### 损失函数设计

损失函数（loss）：关于未知量 $w$、$b$ 的函数 $L(w, b)$，由一组 $w$、$b$ 估测的 $\hat{y}$ 和真实值 $y$ 的差距 $e$ 累计计算得到损失值。

计算预估值 $\hat{y}$ 和真实值 $y$ 的差距有如下几种方式：

- **平均绝对误差（Mean Absolute Error, MAE）**：$e_1 = |y-\hat{y}|$，适用于回归问题
- **均方误差（Mean Squared Error, MSE）**：$e_2 = (y-\hat{y})^2$，适用于回归问题，对大误差更敏感
- **交叉熵损失（Cross Entropy）**：$e_3 = -\sum_{i=1}^{C} y_i \log(\hat{y}_i)$，其中 $C$ 是类别数，适用于多分类问题。在多分类中，$y_i$ 是真实标签（只有一个位置为1，其余为0），$\hat{y}_i$ 是模型预测的第i个类别的概率。求和操作计算所有类别的交叉熵并求和，得到最终的损失值。

累计方式：$L = \frac{1}{N} \sum_{n} e_n$。其中，$N$ 表示训练数据的个数，$e_n$ 表示第 n 个样本的损失值。

以不同的参数计算损失值，画出的等损失线图称为**误差表面（error surface）**，可以直观看出参数取值与损失值的关系。

![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202507311112689.png)

上图中，横轴为参数 $w$ 的取值，纵轴为参数 $b$ 的取值，横纵轴交叉点为损失值，将相同损失值对应的 $(w, b)$ 用线连接就得到等损失线。


### 优化求解

找出一组使得损失最小的 $w$ 和 $b$。具体优化的步骤如下：

#### 随机初始化

初始化参数分别为：$w^0$、$b^0$

#### 参数更新

$w^1 = w^0 - \eta \frac{\partial L}{\partial w} |_{w=w^0}$

$b^1 = b^0 - \eta \frac{\partial L}{\partial b} |_{b=b^0}$

上式中，$\eta$ 为学习率（learning rate），取正值。如果 $\eta$ 越大，那么参数更新量会更大，学习更快，反之则变化小。这一参数需要自己设定，不由机器学习，称为超参数（hyperparameter）。

> $L$ 关于参数 $w$ 的梯度（$\frac{\partial L}{\partial w}$）指向函数值（损失）增加最快的方向，为了使损失变小，所以增加负号，选择最小化损失的方向



**终止条件**：
1. 设定最大迭代次数（如1000次）
2. 梯度接近0（如 $|\frac{\partial L}{\partial w}| < 0.001$）
3. 损失值不再明显下降




#### 优化过程可视化 -- 以单参数模型为例

下面以一个参数 $w$ 来讨论优化过程。

首先，初始化参数 $w=w^0$，然后更新 $w^1 = w^0-\eta \frac{\partial L}{\partial w} |_{w=w^0}$，其中 $\frac{\partial L}{\partial w} |_{w=w^0}$ 在几何上可以理解为损失 $L$ 在 $w^0$ 处的斜率，如果这一数值为负，那么增大 $w$ 就可以实现减小损失，如果这一数值为正，那么减小 $w$ 就能减小损失。

![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202507311910122.png)

> 上图损失函数有一段为负值。一般来说，损失是估计值和真实值的绝对值差距，不可能为负数，如果人工定义时为绝对值减去某个数值，那么就可能为负数。

> 基于梯度下降的优化方法，可能会遇到局部最小值（local minima）问题，也就是陷入一个局部最优中，无法找到全局最小值（global minima），但是在做梯度下降时，真正面对的问题不是局部最小值（待完善）。


#### 优化过程可视化 -- 在二维坐标系中的理解

想象一个二维坐标系，横轴是参数 `w`，纵轴是参数 `b`。对于每一对 `(w, b)`，都可以计算出一个损失值 `L`。我们可以把损失值 `L` 想象成这个二维平面上的“海拔高度”。这样就形成了一个三维的“山谷”地形，也就是上文中提到的**误差表面（error surface）**。我们的目标是走到“山谷”的最低点。

梯度下降的过程如下：

1. **随机选点**：我们随机选择一个出发点 $(w^0, b^0)$。
2. **计算梯度**：在 $(w^0, b^0)$ 这个点，我们计算出梯度 $(\frac{∂L}{∂w}, \frac{∂L}{∂b})$。这个梯度向量指向该点最陡峭的**上坡**方向。
3. **反向移动**：我们将当前位置 $(w^0, b^0)$ 沿着梯度的**相反方向**移动一小步（步长由 `η` 控制），到达新的点 $(w^1, b^1)$。
    - $w^1 = w^0 - η * (\frac{∂L}{∂w})$
    - $b^1 = b^0 - η * (\frac{∂L}{∂b})$
4. **重复**：在新的点 $(w^1, b^1)$ 重复第 2 和第 3 步，一步步地走向“山谷”的更深处，直到我们到达一个局部或全局的最低点（此时梯度接近于零，参数不再更新）。



## 模型进阶与神经网络


下面进一步分析数据特点，对函数重新定义（构建新的模型），同时对之前论述的损失、问题求解等步骤做进一步规范。

构造模型主要包含两个方向：
1. **引入激活函数增加非线性**：从线性模型扩展到非线性模型
2. **扩充特征个数**：增加输入特征的维度



### 方向一：引入激活函数增加非线性

#### 线性模型的局限性

如果模型定义为一个或多个输入特征 $x$ 乘上对应权重，再加上一个偏置，这种模型称为线性模型（linear model），根据输入特征的个数，可以分为一元或多元线性模型。

线性模型往往导致预测结果和前一天的特征 $x$ 成一定比例，比如前一天观看量越大，预测的第二天结果也越大。但实际中可能存在周天至周四观看量很高，但是周五、周六观看量较低的周期性变化，所以线性模型无法模拟真实情况，这称为线性模型的偏差（model bias）。

观看量数据变化是一个复杂的连续曲线，类似下图。然而，任何连续曲线可以由分段线性曲线拟合，所以可以将预测观看量问题转化为如何拟合一个分段线性曲线（piecewise linear curve），并由此设计一个更优的模型。

![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202508111440266.png)


#### 分段线性函数拟合

如下图所示，红色的为一个分段线性曲线，蓝色的为常数和一组hard sigmoid。根据每段区间上各曲线的斜率，可以看出蓝色基本可以拟合出红色的分段线性曲线。

![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202508111444357.png)

因此，可以得出结论：**任意曲线 ≈ 分段线性曲线 = 常数 + 一组hard sigmoid**。



#### sigmoid 与 hard sigmoid
hard sigmoid 是一个分段函数，数学表达式形如：$y = max(0, min(1, (x + 1)/2))$，难以写出简洁的函数表达式，且不易计算梯度值。所以，通常采用 sigmoid 来代替 hard sigmoid，sigmoid 函数表达式为：

$$
y = c \frac{1}{1+e^{wx+b}} = c \sigma(wx+b)
$$

上式中，$c$ 影响高度，$w$ 影响斜线的斜率，$b$ 影响 $x$ 轴平移位置。

![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202508111452228.png)

一般的，任一分段线性曲线可以写出数学表达式：$y = b + \sum_{i} c_i \sigma(b_i+w_i x)$

![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202508111457815.png)

#### ReLU 与 hard sigmoid


表征 hard sigmoid 还可以使用 Rectified Linear Unit(ReLU)，ReLU 函数的一般表达式为：$y = max(0, x)$。

一般的，一个 hard sigmoid 函数需要使用两个 ReLU 来表示。下图直观展示，ReLU 和 hard sigmoid 的关系。其中，红色的 hard sigmoid，可以使用绿色的、由两个 ReLU 表示函数来表示。

![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202509012031352.png)



通常来说，使用 ReLU 来拟合分段线性函数，会使模型性能更优：

1. **计算效率极高**：ReLU 的操作极其简单：`max(0, x)`，这只是一个比较和一个选择操作
2. **梯度消失问题**：ReLU 在正区间梯度恒为1，避免了sigmoid函数的梯度消失问题
3. **实现简单**：相比hard sigmoid需要多个条件判断，ReLU的实现更加直接



### 方向二：扩充特征个数

上面是引入激活函数，将模型从线性模型扩展为非线性模型，从而增强了模型的灵活性（flexible）。

考虑可能多天前的视频观看量数据可能会影响未来一天的观看量，比如存在以周、月、季度的周期变化，所以下面考虑从输入特征个数出发改进模型。

对于 $sigmoid$ 函数来说，只能接收一个数值作为输入，如果增加多个特征作为输入，一个自然的想法是对多个特征做线性组合。第 $i$ 个sigmoid的输入为：$r_i=b_i+w_{i1}x_1+w_{i2}x_2+...w_{ij}x_j+...=b_i+\sum_j{w_{ij}x_j}$，其中，$x_j$ 是第 $j$ 个特征，表示前 $j$ 天的观看量。

最终模型表达式为：
$$
y=b+\sum_i{a_i}=b+\sum{\sigma(r_i)}=b+\sum_i{c_i*\sigma(b_i+\sum_j{w_{ij}x_j})}
$$

矩阵表示形式（以 $i=3$ 为例）：

$$
y = b + [c_1, c_2, c_3] \cdot sigmoid(
\left[\begin{array}{l}
b_1 \\
b_2 \\
b_3
\end{array}\right]+\left[\begin{array}{lll}
w_{11} & w_{12} & w_{13} \\
w_{21} & w_{22} & w_{23} \\
w_{31} & w_{32} & w_{33}
\end{array}\right] \times\left[\begin{array}{l}
x_1 \\
x_2 \\
x_3
\end{array}\right]
) \\
y=b+\vec{C}^{\top} \cdot \operatorname{sigmoid}(\vec{b}+ \mathbf{W} \vec{x})
$$



#### 模型进阶总结

通过引入激活函数或增加特征个数，可以让模型具有更强的表征能力。

**单个特征的形式**：
$$y=b+wx \rightarrow b+\sum_i{c_i*\sigma(b_i+w_i x)}$$

**多个特征的形式**：
$$y=b+\sum_j{w_{ij}x_j} \rightarrow b+\sum_i{c_i*\sigma(b_i+\sum_j{w_{ij}x_j})}$$



### 优化求解的矩阵形式

#### 定义损失

令 $\boldsymbol{\theta}=\{W, b, \vec{c^T}, \vec{b}\}=\left[\begin{array}{c}
\theta_1 \\
\theta_2 \\
\theta_3 \\
\vdots
\end{array}\right]$，损失函数为 $L(\boldsymbol{\theta})$。目标是找到一组使得损失值最小的一组 $\boldsymbol{\theta}$，称为 $\boldsymbol{\theta}^*$。



#### 梯度下降

初始化：$\boldsymbol{\theta}^0$

第一轮参数更新：
$$
\begin{gathered}
\boldsymbol{g_0}=\nabla L\left(\boldsymbol{\theta}_0\right) =
\left[\begin{array}{c}
\left.\frac{\partial L}{\partial \theta_1}\right|_{\boldsymbol{\theta}=\boldsymbol{\theta}_0} \\
\left.\frac{\partial L}{\partial \theta_2}\right|_{\boldsymbol{\theta}=\boldsymbol{\theta}_0} \\
\vdots
\end{array}\right]
\end{gathered}
$$

$$
\boldsymbol{\theta_1} = \left[\begin{array}{c}
\theta_1^1 \\
\theta_1^2 \\
\vdots
\end{array}\right] =
\boldsymbol{\theta_0} - \eta \boldsymbol{g_0}=
\left[\begin{array}{c}
\theta_0^1 \\
\theta_0^2 \\
\vdots
\end{array}\right]-\left[\begin{array}{c}
\left.\eta \frac{\partial L}{\partial \theta_1}\right|_{\boldsymbol{\theta}=\boldsymbol{\theta}_0} \\
\left.\eta \frac{\partial L}{\partial \theta_2}\right|_{\boldsymbol{\theta}=\boldsymbol{\theta}_0} \\
\vdots
\end{array}\right]
$$

第二轮参数更新：
$$
\begin{gathered}
\boldsymbol{g_1}=\nabla L\left(\boldsymbol{\theta}_1\right) =
\left[\begin{array}{c}
\left.\frac{\partial L}{\partial \theta_1}\right|_{\boldsymbol{\theta}=\boldsymbol{\theta}_1} \\
\left.\frac{\partial L}{\partial \theta_2}\right|_{\boldsymbol{\theta}=\boldsymbol{\theta}_1} \\
\vdots
\end{array}\right]
\end{gathered}
$$

$$
\boldsymbol{\theta_2} = \left[\begin{array}{c}
\theta_2^1 \\
\theta_2^2 \\
\vdots
\end{array}\right] =
\boldsymbol{\theta_1} - \eta \boldsymbol{g_1}=
\left[\begin{array}{c}
\theta_1^1 \\
\theta_1^2 \\
\vdots
\end{array}\right]-\left[\begin{array}{c}
\left.\eta \frac{\partial L}{\partial \theta_1}\right|_{\boldsymbol{\theta}=\boldsymbol{\theta}_1} \\
\left.\eta \frac{\partial L}{\partial \theta_2}\right|_{\boldsymbol{\theta}=\boldsymbol{\theta}_1} \\
\vdots
\end{array}\right]
$$

在进行迭代时，会将数据划分成若干份，每份数据称为一个批量（batch），模型会计算在每个批量上的损失，然后更新（update）参数，再计算在下一个批量上的损失，在所有批量上更新完一轮称为一个回合（epoch）。



### 从模型到神经网络的理解

基于前面关于模型改进的讨论，可以引出对神经网络的理解。

#### 神经元的概念

在前面的模型中，我们使用了 sigmoid 或 ReLU 等激活函数来处理输入的多个特征。这些激活函数对输入进行非线性变换的部分，在神经网络中被称为**神经元（neuron）**。

每个神经元的基本结构包括：
1. **输入**：接收来自前一层或多个特征的信息
2. **线性变换**：对输入进行加权求和：$r_i=b_i+w_{i1}x_1+w_{i2}x_2+...w_{ij}x_j+...$
3. **激活函数**：对线性变换结果进行非线性处理：$a_i = \sigma(r_i)$ 或 $a_i = ReLU(r_i)$

#### 神经网络的结构

当我们将多个神经元按照一定的结构组织起来时，就形成了**神经网络（neural network）**：

- **输入层**：接收原始特征数据
- **隐藏层**：包含多个神经元，对输入进行非线性变换
- **输出层**：产生最终的预测结果

每一层中的神经元都接收来自前一层所有神经元的输出，经过自己的处理后再传递给下一层。

#### 深度学习的含义

当神经网络包含多个隐藏层时，就形成了**深度学习（deep learning）**。层数越多，网络的"深度"越大，模型的表达能力也越强。

![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202509012055239.png)



## 模型训练与评估

假设训练集为：$\{(x^1, y^1), (x^2, y^2), ...(x^N, y^N)\}$，测试集为：$\{x^{N+1}, x^{N+2}, ...\}$

模型定义为：$y=f_{\boldsymbol{\theta}}(x)$，其中 $\boldsymbol{\theta}$ 表示模型中的所有参数

损失函数定义为：$L(\boldsymbol{\theta})$

最优的参数组合为：$\boldsymbol{\theta}^*=\arg\min L(\boldsymbol{\theta})$

最终训练好的模型为：$y=f_{\boldsymbol{\theta}^*}(x)$，将测试集作为输入，即可得到模型对测试集的预测结果



### 数据集划分

一般的，会将数据集划分为训练集、验证集、测试集。

其中，训练集作用是训练模型，调整模型的参数；验证集作用是评估不同模型的性能并选择模型；测试集作用是对模型做最终的性能评估。

数据集划分方式一般为：首先将整个数据集按照 8:2 的比例，划分为训练集和测试集，然后对 80% 的训练集按照 8:2 的比例进一步划分为训练集和验证集。也即，训练集：验证集：测试集为64%：16%：20%。



### 模型评估

#### 竞赛中数据集划分

一般竞赛中会有两个测试集，一个是公开榜排名中的测试集（public testing data），另一个是在竞赛结束后用于测试模型的私有测试集（private testing data）。如果过度关注公开榜的测试集来修改模型，可能会影响在private testing data中的结果。竞赛结果的评价，会根据模型在公开榜和私榜结果综合评价，但是往往私榜的权重会更大。

所以在竞赛中，会划分数据集为训练、验证、测试，分别对应竞赛中的公开数据集、公开榜测试集、私榜测试集


#### k折交叉验证（k-fold cross validation）

步骤：假设当前只有训练集和验证集，将训练集划分成 $k$ 份，取第 $1$ 份作为验证集，取后面 $k-1$ 份作为训练集，模型在 $k-1$ 份数据上训练特定的轮数（epoch），然后在验证集上评估，得到验证集上的损失值。然后取第 $2$ 份作为验证集，取剩下 $k-1$ 作为训练集，得到在这一组数据下的损失值。计算 $k$ 份验证集的平均指标值作为该组参数下模型的指标。然后基于相同的步骤评估其他组参数下模型的指标，直到评估完所有的模型。选出最优模型后，基于全量的训练集做最终的训练，然后在测试集上获得评估指标。

作用：避免因为数据集过小，导致模型评估缺乏可靠性

![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202509012057174.png)


## 优化问题及解决方案

一般优化流程：

![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202509012057576.png)

### 常见问题


#### 模型偏差

**表现**：训练集损失值大

**特点**：难以找到一组未知参数，使得模型的损失值降低或降到足够低。也就是，海（模型搜索参数的空间）里根本没有针（最优参数），即使翻遍整个海也不可能找到针。

**解决**：重新设计模型，通过增加输入特征、引入激活函数，进而增强模型的灵活性和表征能力。


#### 优化问题

**表现**：训练集损失值大，且比同类型但更简单的模型损失更大

**特点**：可能存在一组使得模型的损失值足够低的未知参数，但是在优化过程中，梯度下降算法无法找到损失值低的那组参数。也就是，海里有针，但是找不到针的位置。

**区分（模型偏差和优化问题）**：选择一个基础的、比较小或浅的、非深度学习的模型做训练，比如：SVM、随机森林。如果主模型比基础模型的灵活性更强，但是主模型的损失值更大，说明优化存在问题。

**示例**：在 resnet 论文中，在训练和测试集上分别测试 20、56 层的网络，发现随着迭代次数的增加，56 层的网络的误差始终大于 20 层的。56 层的模型灵活性更强，即使只有 20 层工作，其损失值应该可以和 20 层的一致。所以这说明 56 层模型的优化存在不足。
![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202509180744500.png)


#### 过拟合

**表现**：训练集的损失小，测试集损失大。

**特点**：模型过度拟合训练数据，而训练和测试集数据分布存在差异，或者训练集不能反映一些测试集的特征，导致测试集损失大。训练集和测试集遵循相同的数据分布，比如分类问题中，训练和测试集中正负样本比例接近。

> ![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202509180828044.png)

**解决**：
1. 增加训练集，覆盖更多的数据特点。比如：数据增强，在图像处理任务中，对图像做翻转、框选、放缩等。
2. 增加对模型的限制（灵活性降低）。比如：约束模型的表达式（二次函数）；减少参数（减少神经网络中的神经元数量）；使用比较少的输入特征；早停（early stopping）；正则化（regularization）；丢弃（dropout）


#### 不匹配

**表现**：训练集的损失小，测试集损失大。

**特点**：训练集和测试集遵循**不同的数据分布**

**示例**：在图像分类中，用真实物体的彩色照片作为训练集，但用物体的黑白简笔画作为测试集。模型学到的颜色、纹理等特征在测试集上完全无效。

**解决**：需要设法获取与测试集分布相似的数据，或者采用领域自适应 (Domain Adaptation) 等技术。


### 神经网络优化技巧


### 局部最小值与鞍点

现象：随着不断更新参数，训练的损失不再下降，但是损失值仍不满意。

原因：优化到某个阶段，关于参数的微分/梯度为零，导致参数更新停止。

梯度为零的点（临界点， critical point）：局部最小值（local minima）和鞍点（saddle point）。




#### 损失函数变化特点

随着训练进行：
- **训练损失**：逐渐减小，但可能不够小（欠拟合）
- **验证损失**：先减小后增大（过拟合）
- **梯度**：逐渐减小，最终趋于平稳



#### 梯度下降与反向传播的关系

**梯度下降**：一种优化算法，通过计算损失函数关于参数的梯度来更新参数。

**反向传播（Backpropagation）**：计算梯度的高效算法，通过链式法则从输出层向输入层逐层计算梯度。

**关系：**
- 反向传播是梯度下降中计算梯度的具体实现方法
- 梯度下降是优化策略，反向传播是计算工具
- 两者结合构成了神经网络训练的核心

