{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agent 配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, ModelSettings, function_tool, Runner, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from litellm import completion\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('mistral_key')\n",
    "base_url = 'https://api.mistral.ai/v1'\n",
    "chat_model = \"mistral/mistral-small-latest\"\n",
    "\n",
    "# api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "# base_url = \"https://api.deepseek.com/v1\"\n",
    "# chat_model = \"deepseek/deepseek-chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吴淞江畔，春意盎然，上海近日天气宜人，阳光明媚，微风拂面，实为出游佳期。然需注意，偶有阵雨，建议携带雨具，以备不时之需。\n"
     ]
    }
   ],
   "source": [
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is sunny\"\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"天气助手\",\n",
    "    instructions=\"始终用汉赋的形式回答用户\",\n",
    "    model=llm,\n",
    "    tools=[get_weather],  # 定义 tool\n",
    "    model_settings=ModelSettings(temperature=0.2)\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"上海最近适合出去玩吗?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出类型控制\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pydantic.com.cn/#pydantic_1\n",
    "\n",
    "pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='李婷' gender='女' location='上海'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "class Candidate(BaseModel):\n",
    "    name: str\n",
    "    gender: str\n",
    "    location: str\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"简历助手\",\n",
    "    instructions=\"根据要求的格式抽取相应的信息\",\n",
    "    model=llm,\n",
    "    output_type=Candidate,\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"我叫李婷，女，现居上海，想要应聘前台岗位。\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class UserContext:\n",
    "    uid: str\n",
    "    is_pro_user: bool\n",
    "\n",
    "    async def fetch_purchases() -> list[Purchase]:\n",
    "        return ...\n",
    "\n",
    "agent = Agent[UserContext](\n",
    "    ...,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is 47 years old.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from agents import Agent, RunContextWrapper, Runner, function_tool, set_tracing_disabled\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('mistral_key')\n",
    "base_url = 'https://api.mistral.ai/v1'\n",
    "chat_model = \"mistral/mistral-small-latest\"\n",
    "\n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "@dataclass\n",
    "class UserInfo:  \n",
    "    name: str\n",
    "    uid: int\n",
    "\n",
    "@function_tool\n",
    "async def fetch_user_age(wrapper: RunContextWrapper[UserInfo]) -> str:  \n",
    "    # 可以看到，所有的工具都可以访问到这个wrapper.context\n",
    "    return f\"User {wrapper.context.name} is 47 years old\"\n",
    "\n",
    "async def main():\n",
    "    user_info = UserInfo(name=\"John\", uid=123)\n",
    "\n",
    "    agent = Agent[UserInfo](  \n",
    "        name=\"Assistant\",\n",
    "        tools=[fetch_user_age],\n",
    "        model=llm,\n",
    "    )\n",
    "\n",
    "    result = await Runner.run(  \n",
    "        starting_agent=agent,\n",
    "        input=\"What is the age of the user?\",\n",
    "        context=user_info,\n",
    "    )\n",
    "\n",
    "    print(result.final_output)  \n",
    "    # The user John is 47 years old.\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    # asyncio.run(main())\n",
    "\n",
    "await main()\n",
    "\n",
    "\n",
    "# 可以将 if 部分的代码替换成 await main() 吗？\n",
    "# 为什么我运行代码输出结果为：The user is 47 years old.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动态指令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/devtool/anaconda3/envs/openai-agent/lib/python3.10/ast.py:50: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  return compile(source, filename, mode, flags,\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PatInfo.advice() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 54\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mfinal_output)  \n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# if __name__ == \"__main__\":\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#     asyncio.run(main())\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "Cell \u001b[0;32mIn[9], line 43\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m ip_info \u001b[38;5;241m=\u001b[39m PatInfo(ip_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m实用新型\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m agent \u001b[38;5;241m=\u001b[39m Agent[PatInfo](  \n\u001b[1;32m     38\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m     instructions\u001b[38;5;241m=\u001b[39mdynamic_instructions,\n\u001b[1;32m     40\u001b[0m     model\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     41\u001b[0m )\n\u001b[0;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Runner\u001b[38;5;241m.\u001b[39mrun(  \n\u001b[1;32m     44\u001b[0m     starting_agent\u001b[38;5;241m=\u001b[39magent,\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m我想申请专利\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     46\u001b[0m     context\u001b[38;5;241m=\u001b[39mip_info,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mfinal_output)\n",
      "File \u001b[0;32m/devtool/anaconda3/envs/openai-agent/lib/python3.10/site-packages/agents/run.py:199\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run a workflow starting at the given agent. The agent will run in a loop until a final\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03moutput is generated. The loop runs like so:\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m1. The agent is invoked with the given input.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    agent. Agents may perform handoffs, so we don't know the specific type of the output.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m runner \u001b[38;5;241m=\u001b[39m DEFAULT_AGENT_RUNNER\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    200\u001b[0m     starting_agent,\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    202\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m    203\u001b[0m     max_turns\u001b[38;5;241m=\u001b[39mmax_turns,\n\u001b[1;32m    204\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    205\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m    206\u001b[0m     previous_response_id\u001b[38;5;241m=\u001b[39mprevious_response_id,\n\u001b[1;32m    207\u001b[0m )\n",
      "File \u001b[0;32m/devtool/anaconda3/envs/openai-agent/lib/python3.10/site-packages/agents/run.py:395\u001b[0m, in \u001b[0;36mAgentRunner.run\u001b[0;34m(self, starting_agent, input, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    392\u001b[0m )\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_turn \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     input_guardrail_results, turn_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    396\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_input_guardrails(\n\u001b[1;32m    397\u001b[0m             starting_agent,\n\u001b[1;32m    398\u001b[0m             starting_agent\u001b[38;5;241m.\u001b[39minput_guardrails\n\u001b[1;32m    399\u001b[0m             \u001b[38;5;241m+\u001b[39m (run_config\u001b[38;5;241m.\u001b[39minput_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[1;32m    400\u001b[0m             copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28minput\u001b[39m),\n\u001b[1;32m    401\u001b[0m             context_wrapper,\n\u001b[1;32m    402\u001b[0m         ),\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_single_turn(\n\u001b[1;32m    404\u001b[0m             agent\u001b[38;5;241m=\u001b[39mcurrent_agent,\n\u001b[1;32m    405\u001b[0m             all_tools\u001b[38;5;241m=\u001b[39mall_tools,\n\u001b[1;32m    406\u001b[0m             original_input\u001b[38;5;241m=\u001b[39moriginal_input,\n\u001b[1;32m    407\u001b[0m             generated_items\u001b[38;5;241m=\u001b[39mgenerated_items,\n\u001b[1;32m    408\u001b[0m             hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    409\u001b[0m             context_wrapper\u001b[38;5;241m=\u001b[39mcontext_wrapper,\n\u001b[1;32m    410\u001b[0m             run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m    411\u001b[0m             should_run_agent_start_hooks\u001b[38;5;241m=\u001b[39mshould_run_agent_start_hooks,\n\u001b[1;32m    412\u001b[0m             tool_use_tracker\u001b[38;5;241m=\u001b[39mtool_use_tracker,\n\u001b[1;32m    413\u001b[0m             previous_response_id\u001b[38;5;241m=\u001b[39mprevious_response_id,\n\u001b[1;32m    414\u001b[0m         ),\n\u001b[1;32m    415\u001b[0m     )\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     turn_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_single_turn(\n\u001b[1;32m    418\u001b[0m         agent\u001b[38;5;241m=\u001b[39mcurrent_agent,\n\u001b[1;32m    419\u001b[0m         all_tools\u001b[38;5;241m=\u001b[39mall_tools,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m         previous_response_id\u001b[38;5;241m=\u001b[39mprevious_response_id,\n\u001b[1;32m    428\u001b[0m     )\n",
      "File \u001b[0;32m/devtool/anaconda3/envs/openai-agent/lib/python3.10/site-packages/agents/run.py:895\u001b[0m, in \u001b[0;36mAgentRunner._run_single_turn\u001b[0;34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_run_agent_start_hooks:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    887\u001b[0m         hooks\u001b[38;5;241m.\u001b[39mon_agent_start(context_wrapper, agent),\n\u001b[1;32m    888\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    892\u001b[0m         ),\n\u001b[1;32m    893\u001b[0m     )\n\u001b[0;32m--> 895\u001b[0m system_prompt, prompt_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    896\u001b[0m     agent\u001b[38;5;241m.\u001b[39mget_system_prompt(context_wrapper),\n\u001b[1;32m    897\u001b[0m     agent\u001b[38;5;241m.\u001b[39mget_prompt(context_wrapper),\n\u001b[1;32m    898\u001b[0m )\n\u001b[1;32m    900\u001b[0m output_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_schema(agent)\n\u001b[1;32m    901\u001b[0m handoffs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_handoffs(agent)\n",
      "File \u001b[0;32m/devtool/anaconda3/envs/openai-agent/lib/python3.10/site-packages/agents/agent.py:247\u001b[0m, in \u001b[0;36mAgent.get_system_prompt\u001b[0;34m(self, run_context)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m cast(Awaitable[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstructions(run_context, \u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 247\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstructions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstructions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstructions must be a string or a function, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstructions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 31\u001b[0m, in \u001b[0;36mdynamic_instructions\u001b[0;34m(context, agent)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdynamic_instructions\u001b[39m(\n\u001b[1;32m     29\u001b[0m     context: RunContextWrapper[PatInfo], agent: Agent[PatInfo]\n\u001b[1;32m     30\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m用汉赋的句式\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39madvice()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: PatInfo.advice() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from agents import Agent, RunContextWrapper, Runner, function_tool, set_tracing_disabled\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('mistral_key')\n",
    "base_url = 'https://api.mistral.ai/v1'\n",
    "chat_model = \"mistral/mistral-small-latest\"\n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PatInfo:\n",
    "    ip_type: str\n",
    "    def advice() -> str:\n",
    "        if ip_type==\"发明\":\n",
    "            return \"重点为用户讲解发明专利申请的实质审查要求\"\n",
    "        elif ip_type==\"实用新型\":\n",
    "            return \"重点为用户讲解实用新型专利申请的形式审查要求\"\n",
    "\n",
    "def dynamic_instructions(\n",
    "    context: RunContextWrapper[PatInfo], agent: Agent[PatInfo]\n",
    ") -> str:\n",
    "    return f\"用汉赋的句式{context.context.advice()}.\"\n",
    "\n",
    "\n",
    "async def main():\n",
    "    ip_info = PatInfo(ip_type=\"实用新型\")\n",
    "\n",
    "    agent = Agent[PatInfo](  \n",
    "        name=\"Assistant\",\n",
    "        instructions=dynamic_instructions,\n",
    "        model=llm,\n",
    "    )\n",
    "\n",
    "    result = await Runner.run(  \n",
    "        starting_agent=agent,\n",
    "        input=\"我想申请专利\",\n",
    "        context=ip_info,\n",
    "    )\n",
    "\n",
    "    print(result.final_output)  \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
