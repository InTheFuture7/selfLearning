{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务转交"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现方式：\n",
    "1. 主 agent 设置 handoffs 参数，设定接受移交任务的 agent。参考c2.ipynb\n",
    "2. 通过 handoff() 实现移交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, handoff, RunContextWrapper, set_tracing_disabled\n",
    "import asyncio\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('mistral_key')\n",
    "base_url = 'https://api.mistral.ai/v1'\n",
    "chat_model = \"mistral/mistral-small-latest\"\n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "\n",
    "def on_handoff(ctx: RunContextWrapper[None]):\n",
    "    print(\"Handoff called\")\n",
    "\n",
    "\n",
    "history_tutor_agent = Agent(\n",
    "    name=\"History Tutor\",\n",
    "    handoff_description=\"Specialist agent for historical questions\",\n",
    "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "math_tutor_agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    handoff_description=\"Specialist agent for math questions\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "\n",
    "handoff_obj = handoff(\n",
    "    agent=math_tutor_agent,\n",
    "    on_handoff=on_handoff,\n",
    "    tool_name_override=\"custom_handoff_tool\",\n",
    "    tool_description_override=\"Custom description\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=\"You determine which agent to use based on the user's homework question\",\n",
    "    handoffs=[history_tutor_agent, handoff_obj],\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(triage_agent, \"What is the capital of France?\")\n",
    "    print(result.final_output)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追踪\n",
    "\n",
    "Agent 在对话或任务过程中会涉及多轮交互、状态变化、外部工具调用等。如果不持续追踪，Agent 可能“跑偏”、忘记上下文，导致行为失误或效率降低。因此，需要设计机制持续 记录、回顾、更新 当前“状态”与“历史”。\n",
    "\n",
    "记录智能体运行期间的所有事件：包括大模型生成内容、工具调用、交接流程、防护机制触发以及自定义事件等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 禁用追踪\n",
    "\n",
    "1. 通过设置环境变量设置全局关闭追踪功能 `OPENAI_AGENTS_DISABLE_TRACING=1`\n",
    "2. 针对单个程序文件禁用追踪 `set_tracing_disabled(disabled=False)`\n",
    "3. 针对单次运行禁用追踪：将 agents.run.RunConfig.tracing_disabled 设为 True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 追踪与跨度\n",
    "\n",
    "Trace（追踪）包含多个span(跨度)，记录一次完整任务或流程，span是更细粒度的时间段，比如一次llm调用操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 追踪的代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将多次 run() 调用归入同一条规则记录\n",
    "\n",
    "在 logging 中，也可以设置让多个 python 文件的运行日志记录到一个文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, trace\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(name=\"Joke generator\", instructions=\"Tell funny jokes.\")\n",
    "\n",
    "    with trace(\"Joke workflow\"): \n",
    "        first_result = await Runner.run(agent, \"Tell me a joke\")\n",
    "        second_result = await Runner.run(agent, f\"Rate this joke: {first_result.final_output}\")\n",
    "        print(f\"Joke: {first_result.final_output}\")\n",
    "        print(f\"Rating: {second_result.final_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 护栏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为 agent 设置处理任务的边界，具体：检查和验证用户输入；防止恶意使用；节省成本和时间\n",
    "\n",
    "### 类型\n",
    "\n",
    "| 维度         | 输入护栏                                 | 输出护栏                           |\n",
    "| ------------ | ---------------------------------------- | ---------------------------------- |\n",
    "| **装饰器**   | `@input_guardrail`                       | `@output_guardrail`                |\n",
    "| **函数参数** | `input: str \\| list[TResponseInputItem]` | `output: MessageOutput`            |\n",
    "| **数据源**   | 用户原始输入                             | 智能体处理后的输出                 |\n",
    "| **异常类型** | `InputGuardrailTripwireTriggered`        | `OutputGuardrailTripwireTriggered` |\n",
    "| **配置属性** | `input_guardrails=[...]`                 | `output_guardrails=[...]`          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import (\n",
    "    Agent,\n",
    "    GuardrailFunctionOutput,\n",
    "    InputGuardrailTripwireTriggered,\n",
    "    RunContextWrapper,\n",
    "    Runner,\n",
    "    set_tracing_disabled,\n",
    "    TResponseInputItem,\n",
    "    input_guardrail,\n",
    ")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('mistral_key')\n",
    "base_url = 'https://api.mistral.ai/v1'\n",
    "chat_model = \"mistral/mistral-small-latest\"\n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "class MathHomeworkOutput(BaseModel):\n",
    "    is_math_homework: bool\n",
    "    reasoning: str\n",
    "\n",
    "guardrail_agent = Agent( \n",
    "    name=\"Guardrail check\",\n",
    "    instructions=\"Check if the user is asking you to do their math homework.\",\n",
    "    model=llm,\n",
    "    output_type=MathHomeworkOutput,\n",
    ")\n",
    "\n",
    "\n",
    "@input_guardrail\n",
    "async def math_guardrail(ctx: RunContextWrapper[None], agent: Agent, input: str | list[TResponseInputItem]) -> GuardrailFunctionOutput:\n",
    "    result = await Runner.run(guardrail_agent, input, context=ctx.context)\n",
    "\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=result.final_output, \n",
    "        tripwire_triggered=result.final_output.is_math_homework,\n",
    "    )\n",
    "\n",
    "\n",
    "agent = Agent(  \n",
    "    name=\"Customer support agent\",\n",
    "    instructions=\"You are a customer support agent. You help customers with their questions.\",\n",
    "    model=llm,\n",
    "    input_guardrails=[math_guardrail],\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    # This should trip the guardrail\n",
    "    try:\n",
    "        await Runner.run(agent, \"Hello, can you help me solve for x: 2x + 3 = 11?\")\n",
    "        print(\"Guardrail didn't trip - this is unexpected\")\n",
    "\n",
    "    except InputGuardrailTripwireTriggered:\n",
    "        print(\"Math homework guardrail tripped\")\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import (\n",
    "    Agent,\n",
    "    GuardrailFunctionOutput,\n",
    "    OutputGuardrailTripwireTriggered,\n",
    "    RunContextWrapper,\n",
    "    set_tracing_disabled,\n",
    "    Runner,\n",
    "    output_guardrail,\n",
    ")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('mistral_key')\n",
    "base_url = 'https://api.mistral.ai/v1'\n",
    "chat_model = \"mistral/mistral-small-latest\"\n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "class MessageOutput(BaseModel): \n",
    "    response: str\n",
    "\n",
    "class MathOutput(BaseModel): \n",
    "    reasoning: str\n",
    "    is_math: bool\n",
    "\n",
    "guardrail_agent = Agent(\n",
    "    name=\"Guardrail check\",\n",
    "    instructions=\"Check if the output includes any math.\",\n",
    "    model=llm,\n",
    "    output_type=MathOutput,\n",
    ")\n",
    "\n",
    "@output_guardrail\n",
    "async def math_guardrail(ctx: RunContextWrapper, agent: Agent, output: MessageOutput) -> GuardrailFunctionOutput:\n",
    "    result = await Runner.run(guardrail_agent, output.response, context=ctx.context)\n",
    "\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=result.final_output,\n",
    "        tripwire_triggered=result.final_output.is_math,\n",
    "    )\n",
    "\n",
    "agent = Agent( \n",
    "    name=\"Customer support agent\",\n",
    "    instructions=\"You are a customer support agent. You help customers with their questions.\",\n",
    "    model=llm,\n",
    "    output_guardrails=[math_guardrail],\n",
    "    output_type=MessageOutput,\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    # This should trip the guardrail\n",
    "    try:\n",
    "        await Runner.run(agent, \"Hello, can you help me solve for x: 2x + 3 = 11?\")\n",
    "        print(\"Guardrail didn't trip - this is unexpected\")\n",
    "\n",
    "    except OutputGuardrailTripwireTriggered:\n",
    "        print(\"Math output guardrail tripped\")\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编排"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编排（Orchestration）：程序中 agent 的运行流畅，哪些智能体执行任务、以何种顺序执行、后续操作是什么\n",
    "\n",
    "两种方式：\n",
    "\n",
    "1. 大模型自主决策。\n",
    "2. 代码编排。在执行速度、成本控制和性能表现方面提供更确定性的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
