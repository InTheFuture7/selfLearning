{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以将 MCP 想象成 AI 应用程序的\"USB-C端口\"，提供了一种将AI模型连接到不同数据源和工具的标准化方法。\n",
    "\n",
    "传统上，M个AI应用程序连接到N个工具/服务需要 M×N 个自定义集成。而MCP能将复杂的 M×N 问题转化为更易管理的 M+N 问题，每个主机和服务器只需要实现一次MCP标准"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCP 架构组件\n",
    "### 主机 (Host)\n",
    "定义：终端用户直接交互的面向用户的AI应用程序\n",
    "举例：\n",
    "- Anthropic的Claude Desktop\n",
    "- Cursor等AI增强的IDE\n",
    "\n",
    "### 客户端 (Client)\n",
    "定义：主机应用程序中管理与特定MCP服务器通信的组件\n",
    "举例：在Claude Desktop中，负责与MCP服务器交互的模块，每个客户端与单个服务器保持1:1连接\n",
    "\n",
    "### 服务器 (Server)\n",
    "定义：通过MCP协议公开功能（工具、资源、提示）的外部程序或服务\n",
    "举例：\n",
    "- 文件系统访问服务器（提供文件读写功能）\n",
    "- 数据库查询服务器（提供SQL查询功能）\n",
    "- 12306车票查询服务器（提供火车票查询功能）\n",
    "\n",
    "![image.png](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LtZYdQvtDLzN4CwmlHvfFA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 传输方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传输方式是 MCP 协议中定义的客户端和服务器之间通信的具体实现方式。\n",
    "\n",
    "所有传输方式都使用相同的 JSON-RPC 消息格式，但它们在如何传递这些消息上有所不同。\n",
    "\n",
    "![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202507222318840.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCP实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202507222314711.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三方MCP调用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "魔搭MCP市场上的MCP服务分为两类，带**Hosted标签**的为**在线托管服务**，用户可以直接使用；带**Local标签**的为**本地部署服务**，用户需要自行部署。\n",
    "\n",
    "12306-MCP 为例说明如何使用魔搭MCP市场的在线托管服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from agents import Agent, Runner, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from agents.mcp.server import MCPServerSse\n",
    "from agents.model_settings import ModelSettings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "chat_model = \"mistral-small-latest\"\n",
    "base_url=\"https://api.mistral.ai/v1\"\n",
    "api_key=os.getenv('mistral_key')\n",
    "mcp_url = os.getenv('mcp_url')\n",
    "\n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "async def main():\n",
    "    async with MCPServerSse(\n",
    "        params={\n",
    "            \"url\": mcp_url,\n",
    "        }\n",
    "    ) as my_mcp_server: # 建议用这种上下文写法，否则需要手动连接和关闭MCP服务。\n",
    "        agent = Agent(\n",
    "            name=\"Assistant\",\n",
    "            instructions=\"你是一个火车票查询助手，能够查询火车票信息。\",\n",
    "            mcp_servers=[my_mcp_server],\n",
    "            model_settings=ModelSettings(tool_choice=\"required\"),\n",
    "            model=llm,\n",
    "        )\n",
    "\n",
    "        message = \"明天从[]]到[]可以买哪些火车票？\"\n",
    "        print(f\"Running: {message}\")\n",
    "        result = await Runner.run(starting_agent=agent, input=message)\n",
    "        print(result.final_output)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
