{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任务：主 agent 接受来自用户的任务，首先确定问题是否能够回答（护栏边界内），如果在护栏内，那么调用对应的 agent 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from agents import set_tracing_disabled\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "base_url = \"https://api.deepseek.com/v1\"\n",
    "chat_model = \"deepseek/deepseek-chat\"\n",
    "\n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    "    model=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "\n",
    "# 历史\n",
    "history_tutor_agent = Agent(\n",
    "    name=\"History Tutor\",\n",
    "    handoff_description=\"Specialist agent for historical questions\",\n",
    "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "# 数学\n",
    "math_tutor_agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    handoff_description=\"Specialist agent for math questions\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    "    model=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import GuardrailFunctionOutput, InputGuardrail, Agent, Runner\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class HomeworkOutput(BaseModel):\n",
    "    is_homework: bool\n",
    "    reasoning: str\n",
    "\n",
    "guardrail_agent = Agent(\n",
    "    name=\"Guardrail check\",\n",
    "    instructions=\"Check if the user is asking about homework.\",\n",
    "    output_type=HomeworkOutput,\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "async def homework_guardrail(ctx, agent, input_data):\n",
    "    result = await Runner.run(guardrail_agent, input_data, context=ctx.context)\n",
    "    final_output = result.final_output_as(HomeworkOutput)\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=final_output,\n",
    "        tripwire_triggered=not final_output.is_homework,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于用户问题，选择合适的 agent\n",
    "# triage_agent = Agent(\n",
    "#     name=\"Triage Agent\",\n",
    "#     instructions=\"You determine which agent to use based on the user's homework question\",\n",
    "#     handoffs=[history_tutor_agent, math_tutor_agent],\n",
    "#     model=llm,\n",
    "# )\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=\"You determine which agent to use based on the user's homework question\",\n",
    "    # 允许代理将特定任务委派给其他代理\n",
    "    handoffs=[history_tutor_agent, math_tutor_agent],\n",
    "    # 可以对输入到代理的内容进行验证\n",
    "    input_guardrails=[\n",
    "        InputGuardrail(guardrail_function=homework_guardrail),\n",
    "    ],\n",
    "    model=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(triage_agent, \"What is the capital of France?\")\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "# async def main():\n",
    "#     result = await Runner.run(triage_agent, \"does drinking tee good for the body?\")\n",
    "#     print(result.final_output)\n",
    "\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "    # asyncio.run(main())\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "result = await Runner.run(triage_agent, \"does drinking tee good for the body?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "报错没有解决！\n",
    "\n",
    "```\n",
    "BadRequestError: litellm.BadRequestError: DeepseekException - Failed to deserialize the JSON body into the target type: response_format: This response_format type is unavailable now at line 1 column 560\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
